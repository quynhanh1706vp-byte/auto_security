import json
from collections import Counter
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

from flask import Blueprint, current_app, jsonify, request

bp_vsp_v2 = Blueprint("vsp_v2", __name__)

# ===== Helpers: tìm RUN_VSP_FULL_EXT_* mới nhất =====

def get_root_dir() -> Path:
    # ROOT = /home/test/Data/SECURITY_BUNDLE
    return Path(__file__).resolve().parents[2]


def find_latest_vsp_run_dir() -> Optional[Path]:
    root = get_root_dir()
    out_dir = root / "out"
    if not out_dir.is_dir():
        return None

    candidates: List[Tuple[float, Path]] = []
    for p in out_dir.iterdir():
        if not p.is_dir():
            continue
        if not p.name.startswith("RUN_VSP_FULL_EXT_"):
            continue
        try:
            candidates.append((p.stat().st_mtime, p))
        except Exception:
            continue

    if not candidates:
        return None

    candidates.sort(key=lambda x: x[0], reverse=True)
    return candidates[0][1]


def load_findings_unified(run_dir: Optional[Path] = None) -> Tuple[Optional[str], List[Dict[str, Any]]]:
    if run_dir is None:
        run_dir = find_latest_vsp_run_dir()

    if run_dir is None:
        return None, []

    report_dir = run_dir / "report"
    findings_path = report_dir / "findings_unified.json"
    if not findings_path.is_file():
        return run_dir.name, []

    try:
        data = json.loads(findings_path.read_text(encoding="utf-8"))
        if isinstance(data, list):
            return run_dir.name, data
        if isinstance(data, dict) and isinstance(data.get("items"), list):
            return run_dir.name, data["items"]
        return run_dir.name, []
    except Exception as e:
        current_app.logger.exception("[VSP_V2] Lỗi load findings_unified.json: %s", e)
        return run_dir.name, []


# ===== Severity helpers =====

SEVERITY_ORDER = ["CRITICAL", "HIGH", "MEDIUM", "LOW", "INFO", "TRACE"]
SEVERITY_WEIGHT = {
    "CRITICAL": 10.0,
    "HIGH": 5.0,
    "MEDIUM": 2.0,
    "LOW": 1.0,
    "INFO": 0.2,
    "TRACE": 0.0,
}


def normalize_severity(value: Any) -> str:
    if not isinstance(value, str):
        return "TRACE"
    val = value.strip().upper()
    if val in SEVERITY_ORDER:
        return val
    return "TRACE"


def compute_by_severity(findings: List[Dict[str, Any]]) -> Dict[str, int]:
    counts = {sev: 0 for sev in SEVERITY_ORDER}
    for f in findings:
        sev = normalize_severity(
            f.get("severity_effective")
            or f.get("severity")
            or f.get("severity_raw")
        )
        if sev in counts:
            counts[sev] += 1
    return counts


def compute_security_score(by_sev: Dict[str, int]) -> int:
    """
    Score đơn giản:
    - Base = 100
    - Trừ điểm theo weighted sum từng severity.
    - 0 <= score <= 100
    """
    if not by_sev:
        return 100

    total_penalty = 0.0
    for sev, count in by_sev.items():
        total_penalty += SEVERITY_WEIGHT.get(sev, 0.0) * count

    # Scale: mỗi 50 penalty trừ 10 điểm
    score = 100.0 - (total_penalty / 50.0) * 10.0
    score = max(0.0, min(100.0, score))
    return int(round(score))


def _get_field(f: Dict[str, Any], *keys: str) -> Any:
    cur: Any = f
    for k in keys:
        if cur is None:
            return None
        if isinstance(cur, dict):
            cur = cur.get(k)
        else:
            return None
    return cur


# ===== Top risky tool / cwe / module =====

def compute_top_risky_tool(findings: List[Dict[str, Any]]) -> str:
    ctr = Counter()
    for f in findings:
        sev = normalize_severity(f.get("severity_effective") or f.get("severity_raw"))
        if sev not in ("CRITICAL", "HIGH", "MEDIUM"):
            continue
        tool = (f.get("tool") or "").strip()
        if tool:
            ctr[tool] += 1
    if not ctr:
        return "-"
    return ctr.most_common(1)[0][0]


def compute_top_cwe(findings: List[Dict[str, Any]]) -> str:
    ctr = Counter()
    for f in findings:
        sev = normalize_severity(f.get("severity_effective") or f.get("severity_raw"))
        if sev not in ("CRITICAL", "HIGH", "MEDIUM"):
            continue

        vuln = f.get("vuln") or {}
        extra = f.get("extra") or {}

        cwe_ids = vuln.get("cwe_ids")
        if isinstance(cwe_ids, list):
            for c in cwe_ids:
                if isinstance(c, str) and c.strip():
                    ctr[c.strip()] += 1
            continue

        cwe_id = vuln.get("cwe_id") or extra.get("cwe_id") or extra.get("cwe")
        if isinstance(cwe_id, str) and cwe_id.strip():
            ctr[cwe_id.strip()] += 1

    if not ctr:
        return "-"
    return ctr.most_common(1)[0][0]


def compute_top_module(findings: List[Dict[str, Any]]) -> str:
    ctr = Counter()
    for f in findings:
        sev = normalize_severity(f.get("severity_effective") or f.get("severity_raw"))
        if sev not in ("CRITICAL", "HIGH", "MEDIUM"):
            continue

        module = (
            (f.get("module") or "") 
            or (_get_field(f, "code_context", "module") or "")
        ).strip()

        if module:
            ctr[module] += 1

    if not ctr:
        return "-"
    return ctr.most_common(1)[0][0]


# ===== /api/vsp/datasource_v2 =====

# [VSP][CLEANUP] disabled duplicate datasource_v2 route
# @bp_vsp_v2.route("/api/vsp/datasource_v2", methods=["GET"])
def api_vsp_datasource_v2():
    run_dir = find_latest_vsp_run_dir()
    run_id, findings = load_findings_unified(run_dir)

    if run_dir is None or not findings:
        return jsonify({
            "ok": False,
            "run_id": run_id,
            "total": 0,
            "items": [],
            "message": "Không tìm thấy RUN_VSP_FULL_EXT_* hoặc findings_unified.json rỗng.",
        })

    q_severity = request.args.get("severity")
    q_tool = request.args.get("tool")
    q_search = request.args.get("search")
    q_overridden = request.args.get("overridden")

    try:
        limit = int(request.args.get("limit", "200"))
    except ValueError:
        limit = 200
    try:
        offset = int(request.args.get("offset", "0"))
    except ValueError:
        offset = 0

    q_severity_norm = normalize_severity(q_severity) if q_severity else None
    q_tool_lower = q_tool.lower() if q_tool else None
    q_search_lower = q_search.lower() if q_search else None

    overridden_target: Optional[bool] = None
    if q_overridden is not None:
        if q_overridden.lower() in ("1", "true", "yes"):
            overridden_target = True
        elif q_overridden.lower() in ("0", "false", "no"):
            overridden_target = False

    filtered: List[Dict[str, Any]] = []
    for f in findings:
        sev_eff = normalize_severity(f.get("severity_effective") or f.get("severity_raw"))
        tool = (f.get("tool") or "").strip()
        file_path = (f.get("file") or "").strip()
        message = (
            f.get("message")
            or f.get("title")
            or f.get("rule_name")
            or f.get("check_id")
            or ""
        ).strip()
        overridden = bool(f.get("overridden") or False)

        # filter severity
        if q_severity_norm and sev_eff != q_severity_norm:
            continue

        # filter tool
        if q_tool_lower and tool.lower() != q_tool_lower:
            continue

        # filter overridden
        if overridden_target is not None and overridden != overridden_target:
            continue

        # filter search
        if q_search_lower:
            vuln = f.get("vuln") or {}
            cve_id = vuln.get("cve_id") if isinstance(vuln.get("cve_id"), str) else ""
            haystack = " ".join([
                file_path.lower(),
                message.lower(),
                cve_id.lower(),
                tool.lower(),
            ])
            if q_search_lower not in haystack:
                continue

        filtered.append(f)

    total = len(filtered)
    sliced = filtered[offset: offset + limit]

    items: List[Dict[str, Any]] = []
    for f in sliced:
        sev_raw = normalize_severity(f.get("severity_raw"))
        sev_eff = normalize_severity(f.get("severity_effective") or f.get("severity"))
        tool = (f.get("tool") or "").strip()
        file_path = (f.get("file") or "").strip()
        line = f.get("line") or f.get("line_number")
        module = (
            (f.get("module") or "")
            or (_get_field(f, "code_context", "module") or "")
        ).strip()
        language = (_get_field(f, "code_context", "language") or "").strip()
        overridden = bool(f.get("overridden") or False)
        override_rule_id = f.get("override_rule_id")

        asset = f.get("asset") or {}
        vuln = f.get("vuln") or {}
        evidence = f.get("evidence") or {}
        fix_guide = f.get("fix_guide") or {}
        compliance = f.get("compliance") or {}

        message = (
            f.get("message")
            or f.get("title")
            or f.get("rule_name")
            or f.get("check_id")
            or ""
        ).strip()

        items.append({
            "id": f.get("id"),
            "tool": tool,
            "severity_raw": sev_raw,
            "severity_effective": sev_eff,
            "overridden": overridden,
            "override_rule_id": override_rule_id,

            "file": file_path,
            "line": line,
            "module": module,
            "language": language,
            "message": message,

            "asset": asset,
            "vuln": vuln,
            "evidence": {
                "code_snippet": evidence.get("code_snippet")
            },
            "fix_guide": fix_guide,
            "compliance": compliance,
        })

    return jsonify({
        "ok": True,
        "run_id": run_id,
        "total": total,
        "limit": limit,
        "offset": offset,
        "items": items,
        "ts": datetime.utcnow().isoformat() + "Z",
    })


# ===== /api/vsp/dashboard_v3 =====

# [VSP][CLEANUP] disabled duplicate dashboard_v3 route
# @bp_vsp_v2.route("/api/vsp/dashboard_v3", methods=["GET"])
def api_vsp_dashboard_v3():
    run_dir = find_latest_vsp_run_dir()
    run_id, findings = load_findings_unified(run_dir)

    if run_dir is None or not findings:
        return jsonify({
            "ok": False,
            "run_id": run_id,
            "message": "Không tìm thấy RUN_VSP_FULL_EXT_* hoặc findings_unified.json rỗng.",
        })

    by_severity = compute_by_severity(findings)
    total = sum(by_severity.values())
    security_score = compute_security_score(by_severity)
    top_tool = compute_top_risky_tool(findings)
    top_cwe = compute_top_cwe(findings)
    top_module = compute_top_module(findings)

    payload = {
        "ok": True,
        "run_id": run_id,
        "total_findings": total,
        "by_severity": by_severity,
        "severity": by_severity,  # alias cho JS cũ
        "security_score": security_score,
        "top_risky_tool": top_tool,
        "top_cwe": top_cwe,
        "top_module": top_module,
        "ts": datetime.utcnow().isoformat() + "Z",
    }
    return jsonify(payload)
